{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a4f3c5c5",
      "metadata": {
        "id": "a4f3c5c5"
      },
      "source": [
        "# McKean–Vlasov 3D Diffusion — Colab Runner (GPU + Drive + Private Git)\n",
        "\n",
        "**What this does**\n",
        "1. Mounts Google Drive (datasets in, artifacts out)\n",
        "2. Installs JAX (CUDA), Flax, Optax, Torch (CPU-only for `.pt`)\n",
        "3. Clones your **private** GitHub repo/branch without printing your token\n",
        "4. Runs `main.py` on GPU, saving checkpoints/samples to Drive\n",
        "5. Visualizes latest generated samples (`.npy`) as 3D MPL landscapes\n",
        "\n",
        "**Before you run**\n",
        "- Put your dataset `.pt` in Drive, e.g. `/MyDrive/datasets/unified_topological_data_v6_semifast.pt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2c81b926",
      "metadata": {
        "id": "2c81b926",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b3edbc-0fd5-41ce-a8a9-654ed8b5a2fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IN_COLAB: True\n",
            "Mounted at /content/drive\n",
            "Mon Aug 25 07:44:28 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0             58W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "JAX devices: [CudaDevice(id=0)]\n",
            "Backend: gpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2785876187.py:23: DeprecationWarning: jax.lib.xla_bridge.get_backend is deprecated; use jax.extend.backend.get_backend.\n",
            "  print(\"Backend:\", jax.lib.xla_bridge.get_backend().platform)\n"
          ]
        }
      ],
      "source": [
        "# Colab / Drive / GPU setup + deps\n",
        "import os, sys, subprocess, json, time, textwrap, glob\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import google.colab  # type: ignore\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "print(\"IN_COLAB:\", IN_COLAB)\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    # Show GPU\n",
        "    try:\n",
        "        print(subprocess.check_output([\"nvidia-smi\"], text=True))\n",
        "    except Exception as e:\n",
        "        print(\"No NVIDIA GPU visible:\", e)\n",
        "\n",
        "import jax\n",
        "print(\"JAX devices:\", jax.devices())\n",
        "print(\"Backend:\", jax.lib.xla_bridge.get_backend().platform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "11c417db",
      "metadata": {
        "id": "11c417db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3fc348-6abc-4e69-d7f8-5c99c53c4e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CWD: /content/drive/MyDrive/ph-mckeanvlasov-diff/src/mckean-vlasov\n",
            "mckean-vlasov/\n",
            "  .DS_Store\n",
            "  __pycache__/\n",
            "    dataloader.cpython-312.pyc\n",
            "    losses_steps.cpython-312.pyc\n",
            "    losses_steps.py\n",
            "    models.cpython-312.pyc\n",
            "    sampling.cpython-312.pyc\n",
            "  dataloader.py\n",
            "  losses_steps.py\n",
            "  main.py\n",
            "  models.py\n",
            "  run.ipynb\n",
            "  runs/\n",
            "    mv_sde/\n",
            "  sampling.py\n",
            "Found .pt candidates: ['/content/drive/MyDrive/ph-mckeanvlasov-diff/datasets/unified_topological_data_v6_semifast.pt']\n"
          ]
        }
      ],
      "source": [
        "# Point this to the folder in Drive that contains your code:\n",
        "# The folder should have: dataloader.py, models.py, losses_steps.py, sampling.py, main.py, etc.\n",
        "# Example: /content/drive/MyDrive/mckean-vlasov\n",
        "REPO_DIR = Path(\"/content/drive/MyDrive/ph-mckeanvlasov-diff/src/mckean-vlasov\").resolve()\n",
        "\n",
        "assert REPO_DIR.exists(), f\"Repo dir not found: {REPO_DIR}\"\n",
        "os.chdir(REPO_DIR)\n",
        "print(\"CWD:\", Path.cwd())\n",
        "\n",
        "# Quick tree for sanity\n",
        "def tree(path, max_levels=2, prefix=\"\"):\n",
        "    path = Path(path)\n",
        "    print(prefix + path.name + \"/\")\n",
        "    if max_levels <= 0:\n",
        "        return\n",
        "    for p in sorted(path.iterdir()):\n",
        "        if p.is_dir():\n",
        "            tree(p, max_levels-1, prefix + \"  \")\n",
        "        else:\n",
        "            print(prefix + \"  \" + p.name)\n",
        "\n",
        "tree(REPO_DIR, max_levels=2)\n",
        "\n",
        "# Verify required files exist\n",
        "required = [\"dataloader.py\",\"models.py\",\"losses_steps.py\",\"sampling.py\",\"main.py\"]\n",
        "missing = [f for f in required if not (REPO_DIR/f).exists()]\n",
        "assert not missing, f\"Missing files: {missing}\"\n",
        "\n",
        "# Locate dataset .pt (edit if needed)\n",
        "CANDIDATES = glob.glob(\"/content/drive/MyDrive/ph-mckeanvlasov-diff/**/unified_topological_data*.pt\", recursive=True)\n",
        "print(\"Found .pt candidates:\", CANDIDATES[:3])\n",
        "if not CANDIDATES:\n",
        "    print(\">>> If you don't see your dataset, set DATA_PT manually in next cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BQMraSRc0CCh",
      "metadata": {
        "id": "BQMraSRc0CCh"
      },
      "source": [
        "## Env setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "WpyxtD4TJe6B",
      "metadata": {
        "id": "WpyxtD4TJe6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f5f486-3edc-46c4-cebd-24cb5596cd77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/552.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.2/552.2 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m901.7/901.7 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pykeops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keopscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip -q install tqdm gudhi==3.11.0 multipers==2.3.2 geomstats==2.8.0 POT==0.9.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "mgAcPbPBItzZ",
      "metadata": {
        "id": "mgAcPbPBItzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fcf2da6-c93a-41f2-ed45-8ace626b5c26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pykeops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keopscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "PyKeOps set to CPU mode.\n",
            "JAX: 0.5.3 | Devices: [CudaDevice(id=0)]\n",
            "Matmul: (2048, 2048)\n",
            "Torch: 2.8.0+cu126 CUDA avail: True\n",
            "NumPy: 2.0.2 Flax: 0.10.6 Optax: 0.2.5\n"
          ]
        }
      ],
      "source": [
        "# Optional: KeOps forced to CPU (avoid NVCC builds on Colab)\n",
        "%pip -q install pykeops==2.2.3\n",
        "import os\n",
        "os.environ[\"KEOPS_VERBOSE\"]=\"0\"\n",
        "os.environ[\"PYKEOPS_FORCE_BUILD\"]=\"1\"\n",
        "os.environ[\"USE_CUDA\"]=\"0\"\n",
        "os.environ.setdefault(\"XLA_FLAGS\", \"--xla_gpu_autotune_level=1 --xla_gpu_deterministic_ops=true\")\n",
        "print(\"PyKeOps set to CPU mode.\")\n",
        "\n",
        "# Sanity check\n",
        "import os\n",
        "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"  # grow-as-needed GPU memory\n",
        "import jax, jax.numpy as jnp, numpy as np, flax, optax, ml_dtypes\n",
        "print(\"JAX:\", jax.__version__, \"| Devices:\", jax.devices())\n",
        "x = jnp.ones((2048,2048))\n",
        "print(\"Matmul:\", (x@x).block_until_ready().shape)\n",
        "import torch\n",
        "print(\"Torch:\", torch.__version__, \"CUDA avail:\", torch.cuda.is_available())\n",
        "print(\"NumPy:\", np.__version__, \"Flax:\", flax.__version__, \"Optax:\", optax.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "pKPu0XUG8OR-",
      "metadata": {
        "id": "pKPu0XUG8OR-"
      },
      "outputs": [],
      "source": [
        "!export XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
        "!export XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
        "!export XLA_FLAGS=\"--xla_gpu_autotune_level=2 --xla_gpu_enable_triton=false\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96dd91c4",
      "metadata": {
        "id": "96dd91c4"
      },
      "source": [
        "## Repo / Paths\n",
        "Fill in your repo/user/branch and paths. Artifacts will go to Drive under `OUTDIR`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bae62e0b",
      "metadata": {
        "id": "bae62e0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986ab594-bd0b-498b-bbc7-0f927c68d130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training OUTDIR: /content/drive/MyDrive/ph-mckeanvlasov-diff/src/mckean-vlasov/runs/mv_sde/20250825_074507\n",
            "DATA_PT: /content/drive/MyDrive/ph-mckeanvlasov-diff/datasets/unified_topological_data_v6_semifast.pt\n",
            "Launching:\n",
            " /usr/bin/python3 -u main.py --data_pt /content/drive/MyDrive/ph-mckeanvlasov-diff/datasets/unified_topological_data_v6_semifast.pt --outdir /content/drive/MyDrive/ph-mckeanvlasov-diff/src/mckean-vlasov/runs/mv_sde/20250825_074507 --steps 5000 --batch 8 --lr 1.5e-4 --v_pred --use_guidance --lr_guidance 5e-5 --guidance_loss_weight 0.1 --guidance_scale 0.25 --cfg_scale 2.5 --sample_steps 200 --mf_mode rbf --mf_lambda 0.01 --sample_count 512 --cfg_drop 0.1\n",
            "N=1000  vol=(N,H,W,K,C)=(1000, 128, 128, 3, 3)  KS=3  degrees=3  res=128\n",
            "[train] Starting 5000 steps... (v_pred: True, guidance: True)\n",
            "step 00001/5000 | loss=0.7833 (diff=0.7325, guide=0.5087)\n",
            "step 00100/5000 | loss=0.5311 (diff=0.4815, guide=0.4957)\n",
            "step 00200/5000 | loss=0.6918 (diff=0.6469, guide=0.4487)\n",
            "step 00300/5000 | loss=0.2337 (diff=0.2032, guide=0.3044)\n",
            "step 00400/5000 | loss=0.1130 (diff=0.1017, guide=0.1128)\n",
            "step 00500/5000 | loss=0.0466 (diff=0.0358, guide=0.1075)\n",
            "step 00600/5000 | loss=0.0460 (diff=0.0400, guide=0.0600)\n",
            "step 00700/5000 | loss=0.0249 (diff=0.0217, guide=0.0322)\n",
            "step 00800/5000 | loss=0.0222 (diff=0.0198, guide=0.0234)\n",
            "step 00900/5000 | loss=0.0324 (diff=0.0285, guide=0.0392)\n",
            "step 01000/5000 | loss=0.0294 (diff=0.0256, guide=0.0381)\n",
            "step 01100/5000 | loss=0.0264 (diff=0.0240, guide=0.0243)\n",
            "step 01200/5000 | loss=0.0137 (diff=0.0125, guide=0.0124)\n",
            "step 01300/5000 | loss=0.0132 (diff=0.0121, guide=0.0105)\n",
            "step 01400/5000 | loss=0.0205 (diff=0.0177, guide=0.0281)\n",
            "step 01500/5000 | loss=0.0215 (diff=0.0200, guide=0.0145)\n",
            "step 01600/5000 | loss=0.0210 (diff=0.0177, guide=0.0335)\n",
            "step 01700/5000 | loss=0.0281 (diff=0.0261, guide=0.0207)\n",
            "step 01800/5000 | loss=0.0129 (diff=0.0119, guide=0.0104)\n",
            "step 01900/5000 | loss=0.0389 (diff=0.0379, guide=0.0099)\n",
            "step 02000/5000 | loss=0.0117 (diff=0.0104, guide=0.0121)\n",
            "step 02100/5000 | loss=0.0093 (diff=0.0081, guide=0.0124)\n",
            "step 02200/5000 | loss=0.0125 (diff=0.0113, guide=0.0115)\n",
            "step 02300/5000 | loss=0.0142 (diff=0.0124, guide=0.0179)\n",
            "step 02400/5000 | loss=0.0244 (diff=0.0238, guide=0.0058)\n",
            "step 02500/5000 | loss=0.0154 (diff=0.0132, guide=0.0225)\n",
            "step 02600/5000 | loss=0.0238 (diff=0.0211, guide=0.0276)\n",
            "step 02700/5000 | loss=0.0095 (diff=0.0084, guide=0.0104)\n",
            "step 02800/5000 | loss=0.0135 (diff=0.0110, guide=0.0248)\n",
            "step 02900/5000 | loss=0.0166 (diff=0.0141, guide=0.0256)\n",
            "step 03000/5000 | loss=0.0128 (diff=0.0114, guide=0.0147)\n",
            "step 03100/5000 | loss=0.0106 (diff=0.0089, guide=0.0172)\n",
            "step 03200/5000 | loss=0.0089 (diff=0.0077, guide=0.0115)\n",
            "step 03300/5000 | loss=0.0167 (diff=0.0154, guide=0.0121)\n",
            "step 03400/5000 | loss=0.0277 (diff=0.0271, guide=0.0056)\n",
            "step 03500/5000 | loss=0.0127 (diff=0.0112, guide=0.0149)\n",
            "step 03600/5000 | loss=0.0073 (diff=0.0063, guide=0.0100)\n",
            "step 03700/5000 | loss=0.0100 (diff=0.0090, guide=0.0094)\n",
            "step 03800/5000 | loss=0.0093 (diff=0.0082, guide=0.0107)\n",
            "step 03900/5000 | loss=0.0134 (diff=0.0119, guide=0.0149)\n",
            "step 04000/5000 | loss=0.0056 (diff=0.0049, guide=0.0069)\n",
            "step 04100/5000 | loss=0.0089 (diff=0.0085, guide=0.0040)\n",
            "step 04200/5000 | loss=0.0188 (diff=0.0184, guide=0.0044)\n",
            "step 04300/5000 | loss=0.0387 (diff=0.0382, guide=0.0056)\n",
            "step 04400/5000 | loss=0.0096 (diff=0.0092, guide=0.0043)\n",
            "step 04500/5000 | loss=0.0125 (diff=0.0106, guide=0.0191)\n",
            "step 04600/5000 | loss=0.0098 (diff=0.0089, guide=0.0084)\n",
            "step 04700/5000 | loss=0.0111 (diff=0.0099, guide=0.0115)\n",
            "step 04800/5000 | loss=0.0155 (diff=0.0133, guide=0.0219)\n",
            "step 04900/5000 | loss=0.0116 (diff=0.0098, guide=0.0174)\n",
            "step 05000/5000 | loss=0.0095 (diff=0.0085, guide=0.0105)\n",
            "[sample] Starting generation...\n",
            "  Generated 8/512 samples...\n",
            "  Generated 16/512 samples...\n",
            "  Generated 24/512 samples...\n",
            "  Generated 32/512 samples...\n",
            "  Generated 40/512 samples...\n",
            "  Generated 48/512 samples...\n",
            "  Generated 56/512 samples...\n",
            "  Generated 64/512 samples...\n",
            "  Generated 72/512 samples...\n",
            "  Generated 80/512 samples...\n",
            "  Generated 88/512 samples...\n",
            "  Generated 96/512 samples...\n",
            "  Generated 104/512 samples...\n",
            "  Generated 112/512 samples...\n",
            "  Generated 120/512 samples...\n",
            "  Generated 128/512 samples...\n",
            "  Generated 136/512 samples...\n",
            "  Generated 144/512 samples...\n",
            "  Generated 152/512 samples...\n",
            "  Generated 160/512 samples...\n",
            "  Generated 168/512 samples...\n",
            "  Generated 176/512 samples...\n",
            "  Generated 184/512 samples...\n",
            "  Generated 192/512 samples...\n",
            "  Generated 200/512 samples...\n",
            "  Generated 208/512 samples...\n",
            "  Generated 216/512 samples...\n",
            "  Generated 224/512 samples...\n",
            "  Generated 232/512 samples...\n",
            "  Generated 240/512 samples...\n",
            "  Generated 248/512 samples...\n",
            "  Generated 256/512 samples...\n",
            "  Generated 264/512 samples...\n",
            "  Generated 272/512 samples...\n",
            "  Generated 280/512 samples...\n",
            "  Generated 288/512 samples...\n",
            "  Generated 296/512 samples...\n",
            "  Generated 304/512 samples...\n",
            "  Generated 312/512 samples...\n",
            "  Generated 320/512 samples...\n",
            "  Generated 328/512 samples...\n",
            "  Generated 336/512 samples...\n",
            "  Generated 344/512 samples...\n",
            "  Generated 352/512 samples...\n",
            "  Generated 360/512 samples...\n",
            "  Generated 368/512 samples...\n",
            "  Generated 376/512 samples...\n",
            "  Generated 384/512 samples...\n",
            "  Generated 392/512 samples...\n",
            "  Generated 400/512 samples...\n",
            "  Generated 408/512 samples...\n",
            "  Generated 416/512 samples...\n",
            "  Generated 424/512 samples...\n",
            "  Generated 432/512 samples...\n",
            "  Generated 440/512 samples...\n",
            "  Generated 448/512 samples...\n",
            "  Generated 456/512 samples...\n",
            "  Generated 464/512 samples...\n",
            "  Generated 472/512 samples...\n",
            "  Generated 480/512 samples...\n",
            "  Generated 488/512 samples...\n",
            "  Generated 496/512 samples...\n",
            "  Generated 504/512 samples...\n",
            "  Generated 512/512 samples...\n",
            "[done] Saved 512 samples to /content/drive/MyDrive/ph-mckeanvlasov-diff/src/mckean-vlasov/runs/mv_sde/20250825_074507/20250825_074516/samples_landscapes.npz\n",
            "\n",
            "Training exit code: 0\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "import shlex, datetime\n",
        "\n",
        "# === Set paths/args ===\n",
        "# If the auto search in previous cell didn’t find your dataset, set it explicitly here:\n",
        "DATA_PT = CANDIDATES[0] if len(CANDIDATES) else \"/content/drive/MyDrive/ph-mckeanvlasov-diff/datasets/unified_topological_data_v6_semifast.pt\"\n",
        "\n",
        "# Choose an output folder on Drive\n",
        "stamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "OUTDIR = Path(\"/content/drive/MyDrive/ph-mckeanvlasov-diff/src/mckean-vlasov/runs/mv_sde\") / stamp\n",
        "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Training args — tune as you like\n",
        "args = {\n",
        "  \"--data_pt\": DATA_PT,\n",
        "  \"--outdir\": str(OUTDIR),\n",
        "  \"--steps\": \"5000\",\n",
        "  \"--batch\": \"8\",\n",
        "  \"--lr\": \"1.5e-4\",\n",
        "  \"--v_pred\" : \"\",\n",
        "  \"--use_guidance\": \"\",\n",
        "  \"--lr_guidance\": \"5e-5\",\n",
        "  \"--guidance_loss_weight\": \"0.1\",\n",
        "  \"--guidance_scale\": \"0.25\",\n",
        "  \"--cfg_scale\": \"2.5\",\n",
        "  \"--sample_steps\": \"200\",\n",
        "  \"--mf_mode\": \"rbf\",\n",
        "  \"--mf_lambda\": \"0.01\",\n",
        "  \"--sample_count\": \"512\",\n",
        "  \"--cfg_drop\": \"0.1\"\n",
        "}\n",
        "\n",
        "# Pretty print\n",
        "print(\"Training OUTDIR:\", OUTDIR)\n",
        "print(\"DATA_PT:\", DATA_PT)\n",
        "\n",
        "# Build argv\n",
        "argv = [sys.executable, \"-u\", \"main.py\"]\n",
        "for k, v in args.items():\n",
        "    if v == \"\":                       # boolean flags\n",
        "        argv.append(k)\n",
        "    else:\n",
        "        argv.extend([k, v])\n",
        "\n",
        "print('Launching:\\n', ' '.join(shlex.quote(a) for a in argv))\n",
        "\n",
        "# Stream logs live\n",
        "proc = subprocess.Popen(argv, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "try:\n",
        "    for line in proc.stdout:\n",
        "        print(line, end=\"\")\n",
        "finally:\n",
        "    ret = proc.wait()\n",
        "    print(\"\\nTraining exit code:\", ret)\n",
        "    if ret != 0:\n",
        "        raise SystemExit(ret)\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6kMAF25cKe-T",
      "metadata": {
        "id": "6kMAF25cKe-T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}