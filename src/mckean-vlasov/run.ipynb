{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a4f3c5c5",
      "metadata": {
        "id": "a4f3c5c5"
      },
      "source": [
        "# McKean–Vlasov 3D Diffusion — Colab Runner (GPU + Drive + Private Git)\n",
        "\n",
        "**What this does**\n",
        "1. Mounts Google Drive (datasets in, artifacts out)\n",
        "2. Installs JAX (CUDA), Flax, Optax, Torch (CPU-only for `.pt`)\n",
        "3. Clones your **private** GitHub repo/branch without printing your token\n",
        "4. Runs `main.py` on GPU, saving checkpoints/samples to Drive\n",
        "5. Visualizes latest generated samples (`.npy`) as 3D MPL landscapes\n",
        "\n",
        "**Before you run**\n",
        "- Put your dataset `.pt` in Drive, e.g. `/MyDrive/datasets/unified_topological_data_v6_semifast.pt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2c81b926",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c81b926",
        "outputId": "2bc0507f-fb31-410c-b5b3-b4b6bdfd7159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IN_COLAB: True\n",
            "Mounted at /content/drive\n",
            "Fri Aug 22 16:32:06 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0             50W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "JAX devices: [CudaDevice(id=0)]\n",
            "Backend: gpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2785876187.py:23: DeprecationWarning: jax.lib.xla_bridge.get_backend is deprecated; use jax.extend.backend.get_backend.\n",
            "  print(\"Backend:\", jax.lib.xla_bridge.get_backend().platform)\n"
          ]
        }
      ],
      "source": [
        "# Colab / Drive / GPU setup + deps\n",
        "import os, sys, subprocess, json, time, textwrap, glob\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import google.colab  # type: ignore\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "print(\"IN_COLAB:\", IN_COLAB)\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    # Show GPU\n",
        "    try:\n",
        "        print(subprocess.check_output([\"nvidia-smi\"], text=True))\n",
        "    except Exception as e:\n",
        "        print(\"No NVIDIA GPU visible:\", e)\n",
        "\n",
        "import jax\n",
        "print(\"JAX devices:\", jax.devices())\n",
        "print(\"Backend:\", jax.lib.xla_bridge.get_backend().platform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "11c417db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11c417db",
        "outputId": "627028da-e174-47c4-a86c-841108701cdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CWD: /content/drive/MyDrive/ph-mckeanvlasov-diff/src/mckean-vlasov\n",
            "mckean-vlasov/\n",
            "  .DS_Store\n",
            "  __pycache__/\n",
            "    dataloader.cpython-312.pyc\n",
            "    losses_steps.cpython-312.pyc\n",
            "    losses_steps.py\n",
            "    models.cpython-312.pyc\n",
            "    sampling.cpython-312.pyc\n",
            "  dataloader.py\n",
            "  losses_steps.py\n",
            "  main.py\n",
            "  models.py\n",
            "  run.ipynb\n",
            "  runs/\n",
            "    mv_sde/\n",
            "  sampling.py\n",
            "Found .pt candidates: ['/content/drive/MyDrive/ph-mckeanvlasov-diff/datasets/unified_topological_data_v6_semifast.pt']\n"
          ]
        }
      ],
      "source": [
        "# Point this to the folder in Drive that contains your code:\n",
        "# The folder should have: dataloader.py, models.py, losses_steps.py, sampling.py, main.py, etc.\n",
        "# Example: /content/drive/MyDrive/mckean-vlasov\n",
        "REPO_DIR = Path(\"/content/drive/MyDrive/ph-mckeanvlasov-diff/src/mckean-vlasov\").resolve()\n",
        "\n",
        "assert REPO_DIR.exists(), f\"Repo dir not found: {REPO_DIR}\"\n",
        "os.chdir(REPO_DIR)\n",
        "print(\"CWD:\", Path.cwd())\n",
        "\n",
        "# Quick tree for sanity\n",
        "def tree(path, max_levels=2, prefix=\"\"):\n",
        "    path = Path(path)\n",
        "    print(prefix + path.name + \"/\")\n",
        "    if max_levels <= 0:\n",
        "        return\n",
        "    for p in sorted(path.iterdir()):\n",
        "        if p.is_dir():\n",
        "            tree(p, max_levels-1, prefix + \"  \")\n",
        "        else:\n",
        "            print(prefix + \"  \" + p.name)\n",
        "\n",
        "tree(REPO_DIR, max_levels=2)\n",
        "\n",
        "# Verify required files exist\n",
        "required = [\"dataloader.py\",\"models.py\",\"losses_steps.py\",\"sampling.py\",\"main.py\"]\n",
        "missing = [f for f in required if not (REPO_DIR/f).exists()]\n",
        "assert not missing, f\"Missing files: {missing}\"\n",
        "\n",
        "# Locate dataset .pt (edit if needed)\n",
        "CANDIDATES = glob.glob(\"/content/drive/MyDrive/ph-mckeanvlasov-diff/**/unified_topological_data*.pt\", recursive=True)\n",
        "print(\"Found .pt candidates:\", CANDIDATES[:3])\n",
        "if not CANDIDATES:\n",
        "    print(\">>> If you don't see your dataset, set DATA_PT manually in next cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BQMraSRc0CCh",
      "metadata": {
        "id": "BQMraSRc0CCh"
      },
      "source": [
        "## Env setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "WpyxtD4TJe6B",
      "metadata": {
        "id": "WpyxtD4TJe6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b78cb2a-e616-4d58-9018-d6569814ca63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/552.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m522.2/552.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.2/552.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m901.7/901.7 kB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pykeops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keopscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip -q install gudhi==3.11.0 multipers==2.3.2 geomstats==2.8.0 POT==0.9.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "mgAcPbPBItzZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgAcPbPBItzZ",
        "outputId": "041d92df-bb4b-4b94-d4fa-dc59b20e4f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pykeops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keopscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "PyKeOps set to CPU mode.\n",
            "JAX: 0.5.3 | Devices: [CudaDevice(id=0)]\n",
            "Matmul: (2048, 2048)\n",
            "Torch: 2.8.0+cu126 CUDA avail: True\n",
            "NumPy: 2.0.2 Flax: 0.10.6 Optax: 0.2.5\n"
          ]
        }
      ],
      "source": [
        "# Optional: KeOps forced to CPU (avoid NVCC builds on Colab)\n",
        "%pip -q install pykeops==2.2.3\n",
        "import os\n",
        "os.environ[\"KEOPS_VERBOSE\"]=\"0\"\n",
        "os.environ[\"PYKEOPS_FORCE_BUILD\"]=\"1\"\n",
        "os.environ[\"USE_CUDA\"]=\"0\"\n",
        "print(\"PyKeOps set to CPU mode.\")\n",
        "\n",
        "# Sanity check\n",
        "import os\n",
        "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"  # grow-as-needed GPU memory\n",
        "import jax, jax.numpy as jnp, numpy as np, flax, optax, ml_dtypes\n",
        "print(\"JAX:\", jax.__version__, \"| Devices:\", jax.devices())\n",
        "x = jnp.ones((2048,2048))\n",
        "print(\"Matmul:\", (x@x).block_until_ready().shape)\n",
        "import torch\n",
        "print(\"Torch:\", torch.__version__, \"CUDA avail:\", torch.cuda.is_available())\n",
        "print(\"NumPy:\", np.__version__, \"Flax:\", flax.__version__, \"Optax:\", optax.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "pKPu0XUG8OR-",
      "metadata": {
        "id": "pKPu0XUG8OR-"
      },
      "outputs": [],
      "source": [
        "!export XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
        "!export XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
        "!export XLA_FLAGS=\"--xla_gpu_autotune_level=2 --xla_gpu_enable_triton=false\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96dd91c4",
      "metadata": {
        "id": "96dd91c4"
      },
      "source": [
        "## Repo / Paths\n",
        "Fill in your repo/user/branch and paths. Artifacts will go to Drive under `OUTDIR`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bae62e0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bae62e0b",
        "outputId": "b05a59cc-4c8d-4852-985b-f79a44306c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training OUTDIR: /content/drive/MyDrive/ph-mckeanvlasov-diff/src/mckean-vlasov/runs/mv_sde/20250822_163236\n",
            "DATA_PT: /content/drive/MyDrive/ph-mckeanvlasov-diff/datasets/unified_topological_data_v6_semifast.pt\n",
            "Launching:\n",
            " /usr/bin/python3 -u main.py\n",
            "N=1000  vol=(N,H,W,K,C)=(1000, 128, 128, 3, 3)  KS=3  degrees=3  res=128\n",
            "[train] starting…\n",
            "step 00001 | ddpm_loss=11403.67871 | energy_loss=0.70905\n",
            "step 00020 | ddpm_loss=3.20594 | energy_loss=0.68909\n",
            "step 00040 | ddpm_loss=1.75149 | energy_loss=0.73275\n",
            "step 00060 | ddpm_loss=0.60090 | energy_loss=0.57357\n",
            "step 00080 | ddpm_loss=0.51832 | energy_loss=0.59757\n",
            "step 00100 | ddpm_loss=0.38117 | energy_loss=0.58018\n",
            "step 00120 | ddpm_loss=0.66943 | energy_loss=0.48105\n",
            "step 00140 | ddpm_loss=0.53649 | energy_loss=0.39950\n",
            "step 00160 | ddpm_loss=0.21116 | energy_loss=0.49102\n",
            "step 00180 | ddpm_loss=0.33697 | energy_loss=0.49278\n",
            "step 00200 | ddpm_loss=0.54000 | energy_loss=0.49622\n",
            "step 00220 | ddpm_loss=0.27085 | energy_loss=0.55912\n",
            "step 00240 | ddpm_loss=0.16502 | energy_loss=0.41756\n",
            "step 00260 | ddpm_loss=0.10894 | energy_loss=0.53927\n",
            "step 00280 | ddpm_loss=0.21127 | energy_loss=0.56353\n",
            "step 00300 | ddpm_loss=0.11945 | energy_loss=0.56977\n",
            "step 00320 | ddpm_loss=0.13389 | energy_loss=0.57156\n",
            "step 00340 | ddpm_loss=0.16086 | energy_loss=0.42649\n",
            "step 00360 | ddpm_loss=0.10715 | energy_loss=0.46287\n",
            "step 00380 | ddpm_loss=0.27598 | energy_loss=0.43863\n"
          ]
        }
      ],
      "source": [
        "import shlex, datetime\n",
        "\n",
        "# === Set paths/args ===\n",
        "# If the auto search in previous cell didn’t find your dataset, set it explicitly here:\n",
        "DATA_PT = CANDIDATES[0] if len(CANDIDATES) else \"/content/drive/MyDrive/ph-mckeanvlasov-diff/datasets/unified_topological_data_v6_semifast.pt\"\n",
        "\n",
        "# Choose an output folder on Drive\n",
        "stamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "OUTDIR = Path(\"/content/drive/MyDrive/ph-mckeanvlasov-diff/src/mckean-vlasov/runs/mv_sde\") / stamp\n",
        "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Training args — tune as you like\n",
        "args = {}\n",
        "\n",
        "# Pretty print\n",
        "print(\"Training OUTDIR:\", OUTDIR)\n",
        "print(\"DATA_PT:\", DATA_PT)\n",
        "\n",
        "# Build argv\n",
        "argv = [sys.executable, \"-u\", \"main.py\"]\n",
        "for k, v in args.items():\n",
        "    if v == \"\":                       # boolean flags\n",
        "        argv.append(k)\n",
        "    else:\n",
        "        argv.extend([k, v])\n",
        "\n",
        "print('Launching:\\n', ' '.join(shlex.quote(a) for a in argv))\n",
        "\n",
        "# Stream logs live\n",
        "proc = subprocess.Popen(argv, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "try:\n",
        "    for line in proc.stdout:\n",
        "        print(line, end=\"\")\n",
        "finally:\n",
        "    ret = proc.wait()\n",
        "    print(\"\\nTraining exit code:\", ret)\n",
        "    if ret != 0:\n",
        "        raise SystemExit(ret)\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6kMAF25cKe-T",
      "metadata": {
        "id": "6kMAF25cKe-T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}