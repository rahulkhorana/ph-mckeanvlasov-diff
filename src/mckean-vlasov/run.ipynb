{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a4f3c5c5",
      "metadata": {
        "id": "a4f3c5c5"
      },
      "source": [
        "# McKean–Vlasov 3D Diffusion — Colab Runner (GPU + Drive + Private Git)\n",
        "\n",
        "**What this does**\n",
        "1. Mounts Google Drive (datasets in, artifacts out)\n",
        "2. Installs JAX (CUDA), Flax, Optax, Torch (CPU-only for `.pt`)\n",
        "3. Clones your **private** GitHub repo/branch without printing your token\n",
        "4. Runs `main.py` on GPU, saving checkpoints/samples to Drive\n",
        "5. Visualizes latest generated samples (`.npy`) as 3D MPL landscapes\n",
        "\n",
        "**Before you run**\n",
        "- Put your dataset `.pt` in Drive, e.g. `/MyDrive/datasets/unified_topological_data_v6_semifast.pt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c81b926",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c81b926",
        "outputId": "815b0f83-8c91-4758-f4da-5938f89b4873"
      },
      "outputs": [],
      "source": [
        "# Colab / Drive / GPU setup + deps\n",
        "import os, sys, subprocess, json, time, textwrap, glob\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    import google.colab  # type: ignore\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "print(\"IN_COLAB:\", IN_COLAB)\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    # Show GPU\n",
        "    try:\n",
        "        print(subprocess.check_output([\"nvidia-smi\"], text=True))\n",
        "    except Exception as e:\n",
        "        print(\"No NVIDIA GPU visible:\", e)\n",
        "\n",
        "import jax\n",
        "print(\"JAX devices:\", jax.devices())\n",
        "print(\"Backend:\", jax.lib.xla_bridge.get_backend().platform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11c417db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11c417db",
        "outputId": "62f7f335-2c0d-4895-f163-e620fe40c295"
      },
      "outputs": [],
      "source": [
        "# Point this to the folder in Drive that contains your code:\n",
        "# The folder should have: dataloader.py, models.py, losses_steps.py, sampling.py, main.py, etc.\n",
        "# Example: /content/drive/MyDrive/mckean-vlasov\n",
        "REPO_DIR = Path(\"/content/drive/MyDrive/ph-mckeanvlasov-diff/src/mckean-vlasov\").resolve()\n",
        "\n",
        "assert REPO_DIR.exists(), f\"Repo dir not found: {REPO_DIR}\"\n",
        "os.chdir(REPO_DIR)\n",
        "print(\"CWD:\", Path.cwd())\n",
        "\n",
        "# Quick tree for sanity\n",
        "def tree(path, max_levels=2, prefix=\"\"):\n",
        "    path = Path(path)\n",
        "    print(prefix + path.name + \"/\")\n",
        "    if max_levels <= 0:\n",
        "        return\n",
        "    for p in sorted(path.iterdir()):\n",
        "        if p.is_dir():\n",
        "            tree(p, max_levels-1, prefix + \"  \")\n",
        "        else:\n",
        "            print(prefix + \"  \" + p.name)\n",
        "\n",
        "tree(REPO_DIR, max_levels=2)\n",
        "\n",
        "# Verify required files exist\n",
        "required = [\"dataloader.py\",\"models.py\",\"losses_steps.py\",\"sampling.py\",\"main.py\"]\n",
        "missing = [f for f in required if not (REPO_DIR/f).exists()]\n",
        "assert not missing, f\"Missing files: {missing}\"\n",
        "\n",
        "# Locate dataset .pt (edit if needed)\n",
        "CANDIDATES = glob.glob(\"/content/drive/MyDrive/ph-mckeanvlasov-diff/**/unified_topological_data*.pt\", recursive=True)\n",
        "print(\"Found .pt candidates:\", CANDIDATES[:3])\n",
        "if not CANDIDATES:\n",
        "    print(\">>> If you don't see your dataset, set DATA_PT manually in next cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BQMraSRc0CCh",
      "metadata": {
        "id": "BQMraSRc0CCh"
      },
      "source": [
        "## Env setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WpyxtD4TJe6B",
      "metadata": {
        "id": "WpyxtD4TJe6B"
      },
      "outputs": [],
      "source": [
        "%pip -q install gudhi==3.11.0 multipers==2.3.2 geomstats==2.8.0 POT==0.9.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mgAcPbPBItzZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgAcPbPBItzZ",
        "outputId": "fb6a674e-9efa-49ad-b549-98b711960413"
      },
      "outputs": [],
      "source": [
        "# Optional: KeOps forced to CPU (avoid NVCC builds on Colab)\n",
        "%pip -q install pykeops==2.2.3\n",
        "import os\n",
        "os.environ[\"KEOPS_VERBOSE\"]=\"0\"\n",
        "os.environ[\"PYKEOPS_FORCE_BUILD\"]=\"1\"\n",
        "os.environ[\"USE_CUDA\"]=\"0\"\n",
        "print(\"PyKeOps set to CPU mode.\")\n",
        "\n",
        "# Sanity check\n",
        "import os\n",
        "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"  # grow-as-needed GPU memory\n",
        "import jax, jax.numpy as jnp, numpy as np, flax, optax, ml_dtypes\n",
        "print(\"JAX:\", jax.__version__, \"| Devices:\", jax.devices())\n",
        "x = jnp.ones((2048,2048))\n",
        "print(\"Matmul:\", (x@x).block_until_ready().shape)\n",
        "import torch\n",
        "print(\"Torch:\", torch.__version__, \"CUDA avail:\", torch.cuda.is_available())\n",
        "print(\"NumPy:\", np.__version__, \"Flax:\", flax.__version__, \"Optax:\", optax.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pKPu0XUG8OR-",
      "metadata": {
        "id": "pKPu0XUG8OR-"
      },
      "outputs": [],
      "source": [
        "!export XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
        "!export XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
        "!export XLA_FLAGS=\"--xla_gpu_autotune_level=2 --xla_gpu_enable_triton=false\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96dd91c4",
      "metadata": {
        "id": "96dd91c4"
      },
      "source": [
        "## Repo / Paths\n",
        "Fill in your repo/user/branch and paths. Artifacts will go to Drive under `OUTDIR`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bae62e0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bae62e0b",
        "outputId": "91e1414f-902b-48f1-8bcf-278ba199c6c7"
      },
      "outputs": [],
      "source": [
        "import shlex, datetime\n",
        "\n",
        "# === Set paths/args ===\n",
        "# If the auto search in previous cell didn’t find your dataset, set it explicitly here:\n",
        "DATA_PT = CANDIDATES[0] if len(CANDIDATES) else \"/content/drive/MyDrive/ph-mckeanvlasov-diff/datasets/unified_topological_data_v6_semifast.pt\"\n",
        "\n",
        "# Choose an output folder on Drive\n",
        "stamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "OUTDIR = Path(\"/content/drive/MyDrive/ph-mckeanvlasov-diff/src/mckean-vlasov/runs/mv_sde\") / stamp\n",
        "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Training args — tune as you like\n",
        "args = {\n",
        "    \"--data_pt\": DATA_PT,\n",
        "    \"--batch\": \"4\",                # bump to 24/32 on A100 if it fits\n",
        "    \"--steps\": \"20000\",\n",
        "    \"--seed\": \"0\",\n",
        "    \"--lr\": \"2e-4\",\n",
        "    \"--lr_energy\": \"3e-4\",\n",
        "    \"--lr_enc\": \"1e-3\",\n",
        "    \"--T\": \"1000\",\n",
        "    \"--schedule\": \"cosine\",\n",
        "    \"--v_pred\": \"\",                 # flag\n",
        "    \"--ema_decay\": \"0.999\",\n",
        "    \"--use_energy\": \"\",             # flag\n",
        "    \"--energy_scale\": \"0.1\",\n",
        "    \"--energy_tau\": \"0.07\",\n",
        "    \"--energy_gp\": \"1e-4\",\n",
        "    \"--mf_mode\": \"rbf\",\n",
        "    \"--mf_lambda\": \"0.05\",\n",
        "    \"--mf_bandwidth\": \"0.5\",\n",
        "    \"--outdir\": str(OUTDIR),\n",
        "    \"--ckpt_every\": \"2000\",\n",
        "    \"--sample_every\": \"2000\",\n",
        "    \"--sample_steps\": \"250\",\n",
        "    \"--sample_label\": \"-1\",\n",
        "    # If you want classifier-free guidance enabled in your main.py, add:\n",
        "    \"--cfg_drop\": \"0.1\",\n",
        "    \"--cfg_scale\": \"3.0\",\n",
        "    \"--cfg_sched\": \"cosine\",\n",
        "    \"--cfg_strength\": \"5.0\",\n",
        "}\n",
        "\n",
        "# Pretty print\n",
        "print(\"Training OUTDIR:\", OUTDIR)\n",
        "print(\"DATA_PT:\", DATA_PT)\n",
        "\n",
        "# Build argv\n",
        "argv = [sys.executable, \"-u\", \"main.py\"]\n",
        "for k, v in args.items():\n",
        "    if v == \"\":                       # boolean flags\n",
        "        argv.append(k)\n",
        "    else:\n",
        "        argv.extend([k, v])\n",
        "\n",
        "print('Launching:\\n', ' '.join(shlex.quote(a) for a in argv))\n",
        "\n",
        "# Stream logs live\n",
        "proc = subprocess.Popen(argv, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "try:\n",
        "    for line in proc.stdout:\n",
        "        print(line, end=\"\")\n",
        "finally:\n",
        "    ret = proc.wait()\n",
        "    print(\"\\nTraining exit code:\", ret)\n",
        "    if ret != 0:\n",
        "        raise SystemExit(ret)\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6kMAF25cKe-T",
      "metadata": {
        "id": "6kMAF25cKe-T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
